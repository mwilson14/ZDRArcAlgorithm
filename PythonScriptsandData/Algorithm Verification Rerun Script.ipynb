{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script contains the information needed to generate the .pkl files used \n",
    "#in Wilson and Van Den Broeke (in preparation). The original .pkl files and the analysis script \n",
    "#used to compare them to manual data are also included.\n",
    "#Storms M and Y as well as storms 5 and 6 are not available in the Amazon archive and \n",
    "#need to be run on local files which can be downloaded from the NCEI radar archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcalg_framework import multi_case_algorithm_ML1_arcdev\n",
    "from arcalg_local import multi_case_algorithm_ML1_arcdevLOC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "#from partone import multi_case_algorithm_ML1\n",
    "#from RidiculousUnaltered import multi_case_algorithm_ML1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array for storms A, B, BB, CC, D, DD, EE\n",
    "#FFD angle (in degrees)\n",
    "storm_relative_dirs = np.asarray([190, 180, 190, 190, 180, 160, 200])\n",
    "#ZDR threshold\n",
    "zdrlevs = np.asarray([3.25, 3.25, 3.25, 3.25, 3.25, 3.25, 3.25])\n",
    "#KDP threshold for KDP foot\n",
    "kdplevs = np.asarray([1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5])\n",
    "#First Z level used in tracking algorithm\n",
    "REFlevs = np.asarray([45, 45, 45, 45, 45, 45, 30])\n",
    "#Second Z level used in tracking algorithm\n",
    "REFlev1s = np.asarray([50, 50, 50, 50, 50, 50, 35])\n",
    "#Storm size above which the second tracking level will be used to look for embedded cores\n",
    "big_storms = np.asarray([300, 300, 300, 300, 300, 300, 300])\n",
    "#Obsolete parameter\n",
    "zero_z_triggers = np.asarray([17, 17, 17, 17, 17, 17, 17])\n",
    "#Another obsolete parameter\n",
    "storm_to_tracks = np.asarray([1, 2, 2, 0, 2, 4, 6])\n",
    "#Start year for each case\n",
    "years = np.asarray([2013, 2013, 2013, 2013, 2012, 2013, 2012])\n",
    "#Start month\n",
    "months = np.asarray([8, 4, 5, 6, 3, 11, 6])\n",
    "#Start day\n",
    "days = np.asarray([31, 17, 20, 19, 3, 17, 9])\n",
    "#Start hour (UTC)\n",
    "hours = np.asarray([0, 22, 20, 22, 1, 17, 0])\n",
    "#Start minute\n",
    "start_mins = np.asarray([0, 0, 24, 10, 15, 50, 0])\n",
    "#Case duration after the starting time\n",
    "durations = np.asarray([1.1, 2.1, 1.6, 1.1, 1.8, 0.9, 1.1])#0 should should be 1.1\n",
    "#ZDR calibration\n",
    "calibrations = np.asarray([-0.31838281, -0.09084971,  0.10155261, -0.23676067, -0.12648345, -0.46375372, -0.08756084])\n",
    "#Radar station for each case\n",
    "stations = ['KBIS', 'KFDR', 'KINX', 'KLBB', 'KFFC', 'KLOT', 'KMQT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array for storms F, FF, H, HH, I, II, J\n",
    "storm_relative_dirs = np.asarray([180, 230, 150, 210, 160, 190, 170])\n",
    "zdrlevs = np.asarray([3.25, 3.25, 3.25, 3.25, 3.25, 3.25, 3.25])\n",
    "kdplevs = np.asarray([1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5])\n",
    "REFlevs = np.asarray([45, 40, 45, 45, 45, 45, 45])\n",
    "REFlev1s = np.asarray([50, 45, 50, 50, 50, 50, 50])\n",
    "big_storms = np.asarray([300, 300, 300, 300, 300, 300, 300])\n",
    "zero_z_triggers = np.asarray([17, 17, 17, 17, 17, 17, 17])\n",
    "storm_to_tracks = np.asarray([2, 1, 6, 0, 5, 3, 1])\n",
    "years = np.asarray([2012, 2012, 2013, 2013, 2013, 2013, 2012])\n",
    "months = np.asarray([3, 4, 5, 3, 3, 5, 4])\n",
    "days = np.asarray([2, 26, 20, 31, 18, 31, 30])\n",
    "hours = np.asarray([15, 23, 21, 3, 21, 23, 22])\n",
    "start_mins = np.asarray([0, 30, 0, 20, 25, 0, 0])\n",
    "durations = np.asarray([1.5, 1.5, 1.1, 1.4, 1.3, 2.1, 2.0])\n",
    "#calibrations = np.asarray([-0.68, 0.39, -0.14, -0.27, -0.57, -0.45, 0.356])\n",
    "calibrations = np.asarray([-0.69077418,  0.27381103, -0.35858997, -0.3725277,  -0.33369859, -0.48638681, 0.34267983])\n",
    "stations = ['KHTX', 'KOHX', 'KEAX', 'KSRX', 'KFFC', 'KTLX', 'KDDC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array for storms K, M, O, R, W, X, Y, Z\n",
    "#Storms of index 1 and 6 will need local files\n",
    "storm_relative_dirs = np.asarray([120, 190, 170, 200, 190, 170, 150, 190])\n",
    "zdrlevs = np.asarray([3.25, 3.25, 3.25, 3.25, 3.25, 3.25, 3.25, 3.25])\n",
    "kdplevs = np.asarray([1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5])\n",
    "REFlevs = np.asarray([45, 45, 45, 45, 45, 45, 45, 45])\n",
    "REFlev1s = np.asarray([50, 50, 50, 50, 50, 50, 50, 50])\n",
    "big_storms = np.asarray([300, 300, 300, 300, 300, 300, 300, 300])\n",
    "zero_z_triggers = np.asarray([17, 17, 17, 17, 17, 17, 17, 17])\n",
    "storm_to_tracks = np.asarray([2, 0, 1, 2, 0, 0, 1, 1])\n",
    "years = np.asarray([2012, 2013, 2012, 2013, 2013, 2013, 2013, 2013])\n",
    "months = np.asarray([5, 2, 4, 5, 8, 5, 11, 5])\n",
    "days = np.asarray([10, 18, 15, 15, 14, 5, 17, 31])\n",
    "hours = np.asarray([18, 22, 0, 23, 23, 0, 19, 0])\n",
    "start_mins = np.asarray([0, 43, 14, 0, 26, 9, 15, 11])\n",
    "durations = np.asarray([1.0, 1.2, 2.6, 1.5, 1.9, 1.5, 1.1, 1.0])\n",
    "#calibrations = np.asarray([0.055, -0.37, 0.382, -0.05, 0.339, 0.713, -0.2, 0.11])\n",
    "calibrations = np.asarray([-0.258938393, 0.11164869, 0.266559857, -0.19640628,  0.24966193,  0.60389074, -0.25374424, 0.117557395])\n",
    "stations = ['KEWX', 'KSHV', 'KTWX', 'KFWS', 'KAMA', 'KJAX', 'KVWX', 'KINX']\n",
    "localfolder = ['','StormM','','','','','StormY','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storm E\n",
    "storm_relative_dirs = np.asarray([230])\n",
    "zdrlevs = np.asarray([3.25])\n",
    "kdplevs = np.asarray([1.5])\n",
    "REFlevs = np.asarray([45])\n",
    "REFlev1s = np.asarray([50])\n",
    "big_storms = np.asarray([300])\n",
    "zero_z_triggers = np.asarray([17])\n",
    "storm_to_tracks = np.asarray([0])\n",
    "years = np.asarray([2013])\n",
    "months = np.asarray([8])\n",
    "days = np.asarray([28])\n",
    "hours = np.asarray([3])\n",
    "start_mins = np.asarray([10])\n",
    "durations = np.asarray([1.0])\n",
    "#calibrations = np.asarray([-0.71])\n",
    "calibrations = np.asarray([-0.399802913])\n",
    "stations = ['KDTX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now start on the nontornadic storms\n",
    "#Storms 1, 2, 3, 4, 5, 6, 7\n",
    "#Storms 5 and 6 need local files and 7 is missing a sounding\n",
    "#Only index values run 0,2,4\n",
    "storm_relative_dirs = np.asarray([140, 140, 220, 220, 190, 190, 160])\n",
    "zdrlevs = np.asarray([3.25, 3.25, 3.25, 3.25, 3.25, 3.25, 3.25])\n",
    "kdplevs = np.asarray([1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5])\n",
    "REFlevs = np.asarray([45, 45, 45, 45, 45, 45, 45])\n",
    "REFlev1s = np.asarray([50, 50, 50, 50, 50, 50, 50])\n",
    "big_storms = np.asarray([300, 300, 300, 300, 300, 300, 300])\n",
    "zero_z_triggers = np.asarray([17, 17, 17, 17, 17, 17, 17])\n",
    "storm_to_tracks = np.asarray([0, 3, 2, 1, 1, 3, 3])\n",
    "years = np.asarray([2013, 2013, 2013, 2013, 2013, 2013, 2012])\n",
    "months = np.asarray([4, 4, 5, 5, 4, 4, 4])\n",
    "days = np.asarray([27, 27, 30, 30, 22, 22, 30])\n",
    "hours = np.asarray([1, 2, 18, 18, 23, 23, 4])\n",
    "start_mins = np.asarray([0, 0, 9, 40, 20, 25, 25])\n",
    "durations = np.asarray([2.2, 2.2, 1.6, 1.6, 1.7, 1.8, 1.5])\n",
    "#calibrations = np.asarray([-0.742, -0.455, -0.279, -0.379, 0.02, -0.017, 0.224])\n",
    "calibrations = np.asarray([-0.902011267,-0.902011267,-0.50719614,-0.50719614,-0.100394186378,-0.100394186378,-9999])\n",
    "stations = ['KTLX', 'KTLX', 'KTLX', 'KTLX', 'KVNX', 'KVNX', 'KAMA']\n",
    "localfolder = ['','','','','Storm5and6','Storm5and6','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storms 10, 13, 14, 16, 19, 21, 23, 24\n",
    "#Storm 15 skipped since it only produces 1 very small arc object, and storm 22 skipped because it produces none\n",
    "storm_relative_dirs = np.asarray([170, 150, 160, 180, 200, 150, 180, 190])\n",
    "zdrlevs = np.asarray([3.25, 3.25, 3.25, 3.25, 3.25, 3.25, 3.25, 3.25])\n",
    "kdplevs = np.asarray([1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5])\n",
    "REFlevs = np.asarray([45, 45, 45, 45, 45, 45, 47, 45])\n",
    "REFlev1s = np.asarray([50, 50, 50, 50, 50, 50, 52, 50])\n",
    "big_storms = np.asarray([300, 300, 300, 300, 300, 300, 300, 300])\n",
    "zero_z_triggers = np.asarray([25, 17, 17, 17, 17, 25, 17, 17])\n",
    "storm_to_tracks = np.asarray([0, 1, 1, 0, 4, 3, 0, 1])\n",
    "years = np.asarray([2014, 2013, 2013, 2013, 2013, 2014, 2014, 2013])\n",
    "months = np.asarray([9, 10, 3, 6, 10, 4, 5, 8])\n",
    "days = np.asarray([4, 14, 18, 17, 27, 3, 21, 6])\n",
    "hours = np.asarray([5, 19, 20, 19, 0, 2, 1, 23])\n",
    "start_mins = np.asarray([20, 38, 0, 30, 0, 0, 30, 0])\n",
    "durations = np.asarray([1.3, 0.9, 1.1, 1.2, 1.2, 1.8, 0.9, 1.1])\n",
    "#calibrations = np.asarray([-0.623, 0.332, -0.0679, -0.356, -0.281, 0.113, 0.163, 0.206]) 87\n",
    "calibrations = np.asarray([-0.8593222, 0.29232981, -0.27243836,-0.33237107,-0.21629284,0.06499876,-0.07566869,-0.09450731])\n",
    "stations = ['KBIS', 'KDDC', 'KDGX', 'KDTX', 'KFWS', 'KICT', 'KLOT', 'KMPX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storms 26, 27, 28, 29, 30, 32\n",
    "storm_relative_dirs = np.asarray([200, 160, 180, 180, 210, 160])\n",
    "zdrlevs = np.asarray([3.25, 3.25, 3.25, 3.25, 3.25, 3.25])\n",
    "kdplevs = np.asarray([1.5, 1.5, 1.5, 1.5, 1.5, 1.5])\n",
    "REFlevs = np.asarray([40, 45, 45, 45, 45, 45])\n",
    "REFlev1s = np.asarray([45, 50, 50, 50, 50, 50])\n",
    "big_storms = np.asarray([300, 300, 300, 300, 300, 300])\n",
    "zero_z_triggers = np.asarray([17, 17, 17, 17, 17, 17])\n",
    "storm_to_tracks = np.asarray([0, 0, 3, 0, 0, 0])\n",
    "years = np.asarray([2013, 2013, 2013, 2013, 2013,2014])\n",
    "months = np.asarray([4, 7, 5, 5, 7, 5])\n",
    "days = np.asarray([7, 9, 21, 25, 23, 20])\n",
    "hours = np.asarray([23, 23, 1, 21, 20, 21])\n",
    "start_mins = np.asarray([10, 20, 30, 0, 0, 0])\n",
    "durations = np.asarray([1.4, 1.0, 0.7, 1.1, 1.0, 1.0])\n",
    "#calibrations = np.asarray([-0.01, 0.095, 0.15, -0.2143, -0.415, 0.101])\n",
    "calibrations = np.asarray([-0.11826437,  0.13982464,  0.10946657, -0.22040076, -0.38976698, -0.13929619])\n",
    "stations = ['KSGF', 'KABR', 'KDMX', 'KUDX', 'KUDX', 'KFTG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run storms 15 and 22\n",
    "storm_relative_dirs = np.asarray([170, 130])\n",
    "zdrlevs = np.asarray([3.25, 3.25])\n",
    "kdplevs = np.asarray([1.5, 1.5])\n",
    "REFlevs = np.asarray([43, 40])\n",
    "REFlev1s = np.asarray([48, 45])\n",
    "big_storms = np.asarray([300, 300])\n",
    "zero_z_triggers = np.asarray([17, 17])\n",
    "storm_to_tracks = np.asarray([0, 3])\n",
    "years = np.asarray([2013, 2013])\n",
    "months = np.asarray([8, 7])\n",
    "days = np.asarray([13, 4])\n",
    "hours = np.asarray([12, 23])\n",
    "start_mins = np.asarray([20, 0])\n",
    "durations = np.asarray([1.0, 1.6])\n",
    "#calibrations = np.asarray([-0.122, -0.1045])\n",
    "calibrations = np.asarray([-0.31812048,  0.04635963])\n",
    "stations = ['KDIX', 'KJKL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 17:28:42.253778\n",
      "Downloaded KBIS20130831_000147_V06.gz\n",
      "Downloaded KBIS20130831_000603_V06.gz\n",
      "Downloaded KBIS20130831_001018_V06.gz\n",
      "3 out of 3 files downloaded...0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.0 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.0 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Reading\n",
      "in loop\n",
      "17\n",
      "Pre-grid Organization Section\n",
      "KDP Section\n",
      "Grid Section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\pyart\\map\\gates_to_grid.py:177: DeprecationWarning: Barnes weighting function is deprecated. Please use Barnes 2 to be consistent with Pauley and Wu 1990.\n",
      "  \" Pauley and Wu 1990.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Analysis and Masking\n",
      "(-101.7602767944336, 45.77083206176758, <cartopy.crs.PlateCarree object at 0x0000017F5CDC8948>)\n",
      "Testfig Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\Documents\\Python Scripts\\SPORK\\arcalg_framework.py:539: RuntimeWarning: invalid value encountered in true_divide\n",
      "  shaped_ang = (180-np.abs(shaped_ang))*(shaped_ang/np.abs(shaped_ang))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure Saved\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "File Reading\n",
      "in loop\n",
      "17\n",
      "Pre-grid Organization Section\n",
      "KDP Section\n",
      "Grid Section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\pyart\\map\\gates_to_grid.py:177: DeprecationWarning: Barnes weighting function is deprecated. Please use Barnes 2 to be consistent with Pauley and Wu 1990.\n",
      "  \" Pauley and Wu 1990.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Analysis and Masking\n",
      "(-101.7602767944336, 45.77083206176758, <cartopy.crs.PlateCarree object at 0x0000017F5CDC8D08>)\n",
      "Testfig Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\Documents\\Python Scripts\\SPORK\\arcalg_framework.py:539: RuntimeWarning: invalid value encountered in true_divide\n",
      "  shaped_ang = (180-np.abs(shaped_ang))*(shaped_ang/np.abs(shaped_ang))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure Saved\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "File Reading\n",
      "in loop\n",
      "17\n",
      "Pre-grid Organization Section\n",
      "KDP Section\n",
      "Grid Section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\pyart\\map\\gates_to_grid.py:177: DeprecationWarning: Barnes weighting function is deprecated. Please use Barnes 2 to be consistent with Pauley and Wu 1990.\n",
      "  \" Pauley and Wu 1990.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Analysis and Masking\n",
      "(-101.7602767944336, 45.77083206176758, <cartopy.crs.PlateCarree object at 0x0000017F0086E888>)\n",
      "Testfig Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\matts\\AppData\\Local\\Continuum\\anaconda3\\envs\\radar\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\matts\\Documents\\Python Scripts\\SPORK\\arcalg_framework.py:539: RuntimeWarning: invalid value encountered in true_divide\n",
      "  shaped_ang = (180-np.abs(shaped_ang))*(shaped_ang/np.abs(shaped_ang))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure Saved\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "in loop\n",
      "17\n",
      "Fin\n",
      "2020-02-14 18:00:43.311615\n"
     ]
    }
   ],
   "source": [
    "#Loop to run through multiple cases. At the moment, it's only set to run through the first case (KBIS on 31 August 2013)\n",
    "print(datetime.utcnow())\n",
    "#for i in range(len(durations)):\n",
    "#Uncomment line above and comment out the line below to run all of the cases from the cell above\n",
    "#In the call to multi_case_algorithm_ML1_arcdev, the 3.25 and 1.5 are the ZDR and KDP thresholds, the 70 is a placeholder for zero_z_triggers to prevent errors, \n",
    "#the 290 is the storm motion direction used in calculating the separation angle, and track_dis is a tracking threshold\n",
    "#(in km) for the storm tracking algorithm.\n",
    "for i in [0]:\n",
    "    tracks_dataframe, zdroutlines = multi_case_algorithm_ML1_arcdev(storm_relative_dirs[i],3.25,1.5,REFlevs[i],REFlev1s[i],big_storms[i],70,storm_to_tracks[i],years[i],months[i],days[i],hours[i],start_mins[i],durations[i],calibrations[i],stations[i], 290, track_dis=10)\n",
    "    #Uncomment to run on local data\n",
    "    #tracks_dataframe, zdroutlines = multi_case_algorithm_ML1_arcdevLOC(storm_relative_dirs[i],3.25,1.5,REFlevs[i],REFlev1s[i],big_storms[i],70,storm_to_tracks[i],years[i],months[i],days[i],hours[i],start_mins[i],durations[i],calibrations[i],stations[i], localfolder[i], 290, track_dis=10)\n",
    "\n",
    "    tracks_dataframe.to_pickle('ARCDEV'+str(years[i])+str(months[i])+str(days[i])+str(stations[i])+'.pkl')\n",
    "print(datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
